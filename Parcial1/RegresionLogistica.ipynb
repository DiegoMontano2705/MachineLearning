#Diego Fernando Montaño Pérez A01282874
#Creado: 22/02/2021
import sys
imp
ort numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris


def batchGradientDescent(x,y,alpha,threshold):
  n,m = x.shape
  beta = np.ones((np.shape(x)[1],1))
  beta[0] = 0.5
  x_transpose = x.transpose()
  j = 0
  while abs(beta[j+1] - beta[j]) > threshold:
    functLogistica = logit(beta,x) - y
    beta[j+1] = beta[j] - alpha*(np.dot(x_transpose,functLogistica))
    j = j + 1 
  return beta[j],j

def logit(b,x):
  return 1.0 / (1 + np.exp(-(np.dot(x,b))))

def tazadeError(n,y):
  e = 0
  return e
   

def main():  
  dataSet = "genero.txt" # sys.argv[1]  param1: nombre del archivo del dataset.
  trainSetProc = 0.80 # sys.argv[2]  param2: porcentaje de elementos del training set (ocupar valores enteros).  
  testSetProc = 0.20 # sys.argv[3]  param3: porcentaje de elementos del test set (ocupar valores enteros).
  alpha = 0.25 #sys.argv[4]  param4: valor de α.
  threshold = 0.0001 # sys.argv[5]  param5: valor del threshold (1x10^-4).
  semillaGem = 37 # sys.argv[6]  param6: semilla del generador de números pseudoaleatorios.

  #Links a los archivos que se encuentran en Github y se guarda la información en una matriz
  if dataSet == "Default.txt":
    url = "https://raw.githubusercontent.com/DiegoMontano2705/MachineLearning/main/Parcial1/Default.txt"
    data = pd.read_csv(url, sep='\t')
    default = {'Yes': 0, 'No': 1}
    student = {'Yes': 0, 'No': 1}
    data.default = [default[item] for item in data.default]
    data.student = [student[item] for item in data.student]
    x = data[['student','balance','income']] #features del vector de entrada
    y = data['default'] #Categoria a ser predecida
  elif dataSet == "genero.txt":
    url = "https://raw.githubusercontent.com/DiegoMontano2705/MachineLearning/main/Parcial1/genero.txt"
    data = pd.read_csv(url)
    gender = {'Male': 0, 'Female': 1}
    data.Gender = [gender[item] for item in data.Gender]
    x = data[['Height','Weight']] #features del vector de entrada
    y = data['Gender'] #Categoria a ser predecida
  else:
    print("Cant process file")

  #Creando vector de entrenamiento
  x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=testSetProc, random_state=semillaGem)
  x_train = x_train.values  #dataset datos aletorios
  y_train = y_train.values  #dataset datos aletorios

  betaFinal = []
  betaFinal,n = batchGradientDescent(x_train,y_train,alpha,threshold)
  #data.head()


  print("Vector beta =",betaFinal)
  print("Interacciones necesarias para entrenar modelo =",n)
  print("Valor de alpha empleado =",alpha)
  print("Valor de threshold empleado =",threshold)
  #print("Taza de error que tiene el modelo =",tazaError)

if __name__ == '__main__':
  main()
